{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NSemxAQ9IGJv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willygru/chat-with-your-code-repo/blob/master/03_Module_01_Chat_with_Your_Code_LlamaIndex_and_Activeloop_Deep_Lake_for_GitHub_Repositories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9gRt2BXzwASv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc77e2d5-3391-4fcd-ab71-6c5877594ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.5/943.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.4/577.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index==0.9.14.post3 deeplake==3.8.8 openai==1.3.8 cohere==4.37\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvFY0UJz_eDb",
        "outputId": "4259b64a-b03e-4312-d25c-e5ad663be32f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "HBlUeSQ1LAsK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "\n",
        "#os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
        "#os.environ['ACTIVELOOP_TOKEN'] = '<YOUR_ACTIVELOOP_KEY>'"
      ],
      "metadata": {
        "id": "--Q2zk06wElp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's setup the keys\n",
        "\n",
        "!pip install -q python-dotenv\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(userdata.get('env_file_path'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXuyauoR_FaR",
        "outputId": "f9f9b137-b507-4937-e870-474cb9ed0864"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRz8UkYsJOlj",
        "outputId": "dabc8365-6d68-4fdf-ab90-0964a0f865a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "from dotenv import load_dotenv\n",
        "from llama_index import download_loader\n",
        "from llama_hub.github_repo import GithubRepositoryReader, GithubClient\n",
        "from llama_index import VectorStoreIndex\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ADSdoTI4ed",
        "outputId": "843bce13-90f0-46e6-ac10-0cd44b504b54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch and set API keys\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "\n",
        "#Set DeepLake dataset path\n",
        "#dataset_path = \"YOUR_DATASET_PATH\""
      ],
      "metadata": {
        "id": "ds_20IvEI4kk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!printenv\n",
        "#!echo $HOME"
      ],
      "metadata": {
        "id": "tfNcsQf_8VDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_github_url(url):\n",
        "    pattern = r\"https://github\\.com/([^/]+)/([^/]+)\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else (None, None)\n",
        "\n",
        "def validate_owner_repo(owner, repo):\n",
        "    return bool(owner) and bool(repo)\n",
        "\n",
        "def initialize_github_client():\n",
        "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    return GithubClient(github_token)\n"
      ],
      "metadata": {
        "id": "0Z62tvseha4A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for OpenAI API key\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not openai_api_key:\n",
        "    raise EnvironmentError(\"OpenAI API key not found in environment variables\")\n",
        "\n",
        "# Check for GitHub Token\n",
        "github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "if not github_token:\n",
        "    raise EnvironmentError(\"GitHub token not found in environment variables\")\n",
        "\n",
        "# Check for Activeloop Token\n",
        "active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "if not active_loop_token:\n",
        "    raise EnvironmentError(\"Activeloop token not found in environment variables\")"
      ],
      "metadata": {
        "id": "0fOpVzjpGJVd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "github_client = initialize_github_client()\n",
        "download_loader(\"GithubRepositoryReader\")\n",
        "\n",
        "github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "owner, repo = parse_github_url(github_url)\n",
        "print(owner)\n",
        "print(repo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txEebGB7OAQ-",
        "outputId": "fc24daaa-ec9d-42bc-8403-2d63499902ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the GitHub repository URL: https://github.com/willygru/nashville-housing\n",
            "willygru\n",
            "nashville-housing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    owner, repo = parse_github_url(github_url)\n",
        "    if validate_owner_repo(owner, repo):\n",
        "        loader = GithubRepositoryReader(\n",
        "            github_client,\n",
        "            owner=owner,\n",
        "            repo=repo,\n",
        "            filter_file_extensions=(\n",
        "                [\".sql\", \".py\", \".js\", \".ts\", \".md\"],\n",
        "                #[\".ipynb\", \".py\", \".js\", \".ts\", \".md\"],\n",
        "                #[\".py\", \".js\", \".ts\", \".md\"],\n",
        "                GithubRepositoryReader.FilterType.INCLUDE,\n",
        "            ),\n",
        "            verbose=False,\n",
        "            concurrent_requests=5,\n",
        "        )\n",
        "        print(f\"Loading {repo} repository by {owner}\")\n",
        "        docs = loader.load_data(branch=\"main\")\n",
        "        print(\"Documents uploaded:\")\n",
        "        for doc in docs:\n",
        "            print(doc.metadata)\n",
        "        break  # Exit the loop once the valid URL is processed\n",
        "    else:\n",
        "        print(\"Invalid GitHub URL. Please try again.\")\n",
        "        github_url = input(\"Please enter the GitHub repository URL: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oclg92d4N_1D",
        "outputId": "5142b3ad-6719-4174-9497-3970e53482d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading nashville-housing repository by willygru\n",
            "Documents uploaded:\n",
            "{'file_path': 'README.md', 'file_name': 'README.md', 'url': 'https://github.com/willygru/nashville-housing/blob/main/README.md'}\n",
            "{'file_path': 'code/SQLQueryNashvilleHousing.sql', 'file_name': 'SQLQueryNashvilleHousing.sql', 'url': 'https://github.com/willygru/nashville-housing/blob/main/code/SQLQueryNashvilleHousing.sql'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Uploading to vector store...\")\n",
        "\n",
        "    # ====== Create vector store and upload data ======\n",
        "\n",
        "vector_store = DeepLakeVectorStore(\n",
        "    #dataset_path=userdata.get('dataset_path'),\n",
        "    dataset_path='hub://your_org/repository_db',\n",
        "    overwrite=True,\n",
        "    runtime={\"tensor_db\": True},\n",
        ")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(docs, storage_context=storage_context)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6fXXmRNafoW",
        "outputId": "b20d7207-f0f5-41b3-d59b-40990a8f5351"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading to vector store...\n",
            "Your Deep Lake dataset has been successfully created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading data to deeplake dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n",
            "/"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://your_org/repository_db', tensors=['text', 'metadata', 'embedding', 'id'])\n",
            "\n",
            "  tensor      htype      shape     dtype  compression\n",
            "  -------    -------    -------   -------  ------- \n",
            "   text       text      (2, 1)      str     None   \n",
            " metadata     json      (2, 1)      str     None   \n",
            " embedding  embedding  (2, 1536)  float32   None   \n",
            "    id        text      (2, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Include a simple question to test.\n",
        "intro_question = \"What is the repository about?\"\n",
        "print(f\"Test question: {intro_question}\")\n",
        "print(\"=\" * 50)\n",
        "answer = query_engine.query(intro_question)\n",
        "\n",
        "print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_Lh6H5Caqzt",
        "outputId": "4999815a-36d9-4995-acdc-6da95144e3df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test question: What is the repository about?\n",
            "==================================================\n",
            "Answer: The repository is about cleaning Nashville housing data. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
        "    if user_question.lower() == \"exit\":\n",
        "        print(\"Exiting, thanks for chatting!\")\n",
        "        break\n",
        "\n",
        "    print(f\"Your question: {user_question}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    answer = query_engine.query(user_question)\n",
        "    print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzT6kOy0awiN",
        "outputId": "a9b2277e-e9f0-46bc-e060-4193d111d4fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your question (or type 'exit' to quit): What is the repository name?\n",
            "Your question: What is the repository name?\n",
            "==================================================\n",
            "Answer: The repository name is \"nashville-housing\". \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): What columns were droped?\n",
            "Your question: What columns were droped?\n",
            "==================================================\n",
            "Answer: The columns that were dropped in the SQL query are OwnerAddress, TaxDistrict, PropertyAddress, and\n",
            "SaleDate. \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): Was any column updated?\n",
            "Your question: Was any column updated?\n",
            "==================================================\n",
            "Answer: Yes, columns were updated in the SQL query. \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): Which ones?\n",
            "Your question: Which ones?\n",
            "==================================================\n",
            "Answer: The query is asking for clarification on which specific actions or steps are being referred to in\n",
            "the given context. \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): Which columns were updated?\n",
            "Your question: Which columns were updated?\n",
            "==================================================\n",
            "Answer: The columns that were updated in the SQL query are: - SaleDateConverted - PropertyAddress -\n",
            "PropertySplitAddress - PropertySplitCity - OwnerSplitAddress - OwnerSplitCity - OwnerSplitState -\n",
            "SoldAsVacant \n",
            "\n",
            "Please enter your question (or type 'exit' to quit): exit\n",
            "Exiting, thanks for chatting!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python main function"
      ],
      "metadata": {
        "id": "NSemxAQ9IGJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_github_url(url):\n",
        "    pattern = r\"https://github\\.com/([^/]+)/([^/]+)\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else (None, None)\n",
        "\n",
        "def validate_owner_repo(owner, repo):\n",
        "    return bool(owner) and bool(repo)\n",
        "\n",
        "def initialize_github_client():\n",
        "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    return GithubClient(github_token)\n",
        "\n",
        "def main():\n",
        "    import os\n",
        "    import textwrap\n",
        "    from dotenv import load_dotenv\n",
        "    from llama_index import download_loader\n",
        "    from llama_hub.github_repo import GithubRepositoryReader, GithubClient\n",
        "    from llama_index import VectorStoreIndex\n",
        "    from llama_index.vector_stores import DeepLakeVectorStore\n",
        "    from llama_index.storage.storage_context import StorageContext\n",
        "    import re\n",
        "\n",
        "    # Load environment variables\n",
        "    load_dotenv()\n",
        "\n",
        "    # Fetch and set API keys\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "    #dataset_path = os.getenv(\"DATASET_PATH\")\n",
        "\n",
        "    # Check for OpenAI API key\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not openai_api_key:\n",
        "        raise EnvironmentError(\"OpenAI API key not found in environment variables\")\n",
        "\n",
        "    # Check for GitHub Token\n",
        "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
        "    if not github_token:\n",
        "        raise EnvironmentError(\"GitHub token not found in environment variables\")\n",
        "\n",
        "    # Check for Activeloop Token\n",
        "    active_loop_token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "    if not active_loop_token:\n",
        "        raise EnvironmentError(\"Activeloop token not found in environment variables\")\n",
        "\n",
        "    github_client = initialize_github_client()\n",
        "    download_loader(\"GithubRepositoryReader\")\n",
        "\n",
        "    github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "    owner, repo = parse_github_url(github_url)\n",
        "\n",
        "    while True:\n",
        "        owner, repo = parse_github_url(github_url)\n",
        "        if validate_owner_repo(owner, repo):\n",
        "            loader = GithubRepositoryReader(\n",
        "                github_client,\n",
        "                owner=owner,\n",
        "                repo=repo,\n",
        "                filter_file_extensions=(\n",
        "                    #[\".py\", \".js\", \".ts\", \".md\"],\n",
        "                    [\".sql\", \".py\", \".js\", \".ts\", \".md\"],\n",
        "                    #[\".ipynb\", \".py\", \".js\", \".ts\", \".md\"],\n",
        "                    GithubRepositoryReader.FilterType.INCLUDE,\n",
        "                ),\n",
        "                verbose=False,\n",
        "                concurrent_requests=5,\n",
        "            )\n",
        "            print(f\"Loading {repo} repository by {owner}\")\n",
        "            docs = loader.load_data(branch=\"main\")\n",
        "            print(\"Documents uploaded:\")\n",
        "            for doc in docs:\n",
        "                print(doc.metadata)\n",
        "            break  # Exit the loop once the valid URL is processed\n",
        "        else:\n",
        "            print(\"Invalid GitHub URL. Please try again.\")\n",
        "            github_url = input(\"Please enter the GitHub repository URL: \")\n",
        "\n",
        "    print(\"Uploading to vector store...\")\n",
        "\n",
        "    # ====== Create vector store and upload data ======\n",
        "\n",
        "    vector_store = DeepLakeVectorStore(\n",
        "        #dataset_path=userdata.get('dataset_path'),\n",
        "        dataset_path='hub://your_org/repository_db',\n",
        "        overwrite=True,\n",
        "        runtime={\"tensor_db\": True},\n",
        "    )\n",
        "\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(docs, storage_context=storage_context)\n",
        "    query_engine = index.as_query_engine()\n",
        "\n",
        "    # Include a simple question to test.\n",
        "    intro_question = \"What is the repository about?\"\n",
        "    print(f\"Test question: {intro_question}\")\n",
        "    print(\"=\" * 50)\n",
        "    answer = query_engine.query(intro_question)\n",
        "\n",
        "    print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n",
        "    while True:\n",
        "        user_question = input(\"Please enter your question (or type 'exit' to quit): \")\n",
        "        if user_question.lower() == \"exit\":\n",
        "            print(\"Exiting, thanks for chatting!\")\n",
        "            break\n",
        "\n",
        "        print(f\"Your question: {user_question}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        answer = query_engine.query(user_question)\n",
        "        print(f\"Answer: {textwrap.fill(str(answer), 100)} \\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "qA0GFZm4I4y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment"
      ],
      "metadata": {
        "id": "mtGKUVg3wI0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "sKHDHMsIwIGp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}